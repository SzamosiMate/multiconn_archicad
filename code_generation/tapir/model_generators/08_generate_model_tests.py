import json
import copy
import re
from typing import Any, Dict, Set

from code_generation.tapir.paths import tapir_paths

KNOWN_XFAILURES = {}

SCHEMAS_TO_PATCH = {"GetHotlinksResult", "GetDetailsOfElementsResult"}


def collect_dependencies_recursively(
    name: str, all_definitions: Dict[str, Any], collected_defs: Dict[str, Any], processed: Set[str]
):
    """Recursively collects all schemas referenced by a given schema name."""
    if name in processed:
        return
    processed.add(name)
    if name not in all_definitions:
        print(f"   ⚠️ Warning: Definition for '{name}' not found in master schema.")
        return
    definition = all_definitions[name]
    collected_defs[name] = definition
    content_str = json.dumps(definition)
    dependencies = re.findall(r'"#/\$defs/(\w+)"', content_str)
    for dep_name in set(dependencies):
        collect_dependencies_recursively(dep_name, all_definitions, collected_defs, processed)


def patch_schema_definitions(definitions: dict, model_name_to_test: str) -> dict:
    """
    Applies patches to fix recursion or other issues specific to Tapir schemas
    that cause Hypothesis to fail or be too slow.
    """
    patched_defs = copy.deepcopy(definitions)

    if model_name_to_test == "GetHotlinksResult":
        if "Hotlink" in patched_defs and "properties" in patched_defs["Hotlink"]:
            patched_defs["Hotlink"]["properties"].pop("children", None)
            print(f"    - Applied patch to 'Hotlink' schema for {model_name_to_test} test (removed recursion).")

    if model_name_to_test == "GetDetailsOfElementsResult":
        if "TypeSpecificDetails" in patched_defs:
            patched_defs["TypeSpecificDetails"] = {"$ref": "#/$defs/WallDetails"}
            print(f"    - Patched 'TypeSpecificDetails' to be only WallDetails for {model_name_to_test} test.")

        item_schema = patched_defs["GetDetailsOfElementsResult"]["properties"]["detailsOfElements"]["items"]
        if "properties" in item_schema and "type" in item_schema["properties"]:
            item_schema["properties"]["type"] = {"const": "Wall"}
            print(f"    - Patched element 'type' discriminator to be 'Wall' for {model_name_to_test} test.")

    return patched_defs


def main():
    """
    Generates a pytest file that performs runtime validation for BOTH the
    Pydantic models and their corresponding TypedDicts using typeguard.
    """
    print("--- Starting Tapir API Combined Test File Generation (Pydantic + typeguard) ---")

    try:
        with open(tapir_paths.MASTER_SCHEMA_OUTPUT, "r", encoding="utf-8") as f:
            master_schema = json.load(f)
        with open(tapir_paths.COMMAND_MODELS_NAMES_OUTPUT, "r", encoding="utf-8") as f:
            command_model_names = json.load(f)
    except FileNotFoundError as e:
        print(f"❌ Error: A required file was not found. Please run the full pipeline. ({e})")
        return

    output_path = tapir_paths.GENERATED_TESTS_OUTPUT
    all_definitions_master = master_schema.get("$defs", {})

    file_header = f"""
# This file is automatically generated by the pipeline. Do not edit directly.

import pytest
import json
from hypothesis import given, settings, HealthCheck
from hypothesis_jsonschema import from_schema
from typeguard import check_type

# Import modules with aliases to avoid name collisions and improve clarity
import multiconn_archicad.models.tapir.commands as models
import multiconn_archicad.dicts.tapir.commands as dicts

# Increase deadline and disable the 'too_slow' health check for complex models.
settings.register_profile("ci", deadline=1000, suppress_health_check=[HealthCheck.too_slow])
settings.load_profile("ci")
pytestmark = pytest.mark.generated
"""

    test_functions = []
    print("\n⚙️  Generating tests with minimal, self-contained schemas...")
    for model_name in sorted(command_model_names):
        xfail_marker = ""
        if model_name in KNOWN_XFAILURES:
            reason = KNOWN_XFAILURES[model_name]
            xfail_marker = f'@pytest.mark.xfail(reason="{reason}", strict=True)'

        source_definitions = all_definitions_master
        if model_name in SCHEMAS_TO_PATCH:
            print(f"   - Applying specific patch for model: {model_name}")
            source_definitions = patch_schema_definitions(all_definitions_master, model_name)

        minimal_definitions = {}
        collect_dependencies_recursively(model_name, source_definitions, minimal_definitions, set())

        temp_schema_for_test = {
            "$schema": "http://json-schema.org/draft-07/schema#",
            "$defs": minimal_definitions,
            "$ref": f"#/$defs/{model_name}",
        }
        schema_as_string = repr(json.dumps(temp_schema_for_test))

        test_function = f"""

{xfail_marker}
@given(data=from_schema(json.loads({schema_as_string})))
def test_runtime_validation_{model_name}(data: dict):
    try:
        check_type(data, dicts.{model_name})
    except Exception as e:
        pytest.fail(f"Typeguard validation failed for TypedDict 'dicts.{model_name}' with data: {{repr(data)}}\\nError: {{e}}")

    try:
        models.{model_name}.model_validate(data)
    except Exception as e:
        pytest.fail(f"Pydantic validation failed for model 'models.{model_name}' with data: {{repr(data)}}\\nError: {{e}}")

"""
        test_functions.append(test_function)

    final_content = file_header + "".join(test_functions)
    output_path.write_text(final_content, encoding="utf-8")

    print(f"\n✅ Successfully generated {len(test_functions)} tests.")
    print(f"   Marked {len(KNOWN_XFAILURES)} tests as xfail.")
    print(f"   Applied patches to {len(SCHEMAS_TO_PATCH)} test schemas.")
    print(f"   Test file created at: {output_path}")


if __name__ == "__main__":
    main()
